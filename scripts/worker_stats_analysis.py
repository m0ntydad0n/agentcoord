#!/usr/bin/env python3
"""
Analyze worker contributions and estimate token usage.
"""

import os
import subprocess

print("ðŸ“Š WORKER CONTRIBUTION ANALYSIS")
print("=" * 80)
print()

# Get file changes
result = subprocess.run(
    ['git', 'diff', '--numstat', 'HEAD~1', 'HEAD'],
    capture_output=True,
    text=True,
    cwd='/Users/johnmonty/agentcoord'
)

files = {}
total_added = 0
total_removed = 0

for line in result.stdout.strip().split('\n'):
    if not line:
        continue
    parts = line.split('\t')
    if len(parts) == 3:
        added, removed, filename = parts
        if added != '-' and removed != '-':
            files[filename] = {
                'added': int(added),
                'removed': int(removed)
            }
            total_added += int(added)
            total_removed += int(removed)

# Group files by likely worker
worker_files = {
    'TUI-Worker-1 (Core TUI)': [
        'agentcoord/tui.py',
        'agentcoord/tui/__init__.py',
        'agentcoord/tui/app.py',
    ],
    'TUI-Worker-2 (Onboarding)': [
        'agentcoord/onboarding.py',
    ],
    'TUI-Worker-3 (CLI Integration)': [
        'agentcoord/cli.py',
        'agentcoord/__main__.py',
    ],
    'TUI-Worker-4 (Planning)': [
        'agentcoord/planner.py',
    ]
}

print("Code Generated by Worker:\n")
print(f"{'Worker':<30} {'Files':<6} {'Lines Added':<15} {'Est. Tokens':<15} {'Est. Cost'}")
print("-" * 80)

grand_total_lines = 0
grand_total_tokens = 0
grand_total_cost = 0

for worker, file_list in worker_files.items():
    lines = 0
    for f in file_list:
        if f in files:
            lines += files[f]['added']
    
    # Estimate tokens (rough: 1 line of code â‰ˆ 30 tokens input + output)
    # Input: task description (~500 tokens) + context (~1000)
    # Output: code generation (~20 tokens per line)
    est_tokens = 1500 + (lines * 20)  # Input context + code generation
    
    # Estimate cost (assuming Sonnet at $3/1M tokens)
    est_cost = (est_tokens / 1_000_000) * 3.0
    
    grand_total_lines += lines
    grand_total_tokens += est_tokens
    grand_total_cost += est_cost
    
    file_count = len([f for f in file_list if f in files])
    
    print(f"{worker:<30} {file_count:<6} {lines:<15,} {est_tokens:<15,} ${est_cost:.4f}")

print("-" * 80)
print(f"{'TOTAL':<30} {'':<6} {grand_total_lines:<15,} {grand_total_tokens:<15,} ${grand_total_cost:.4f}")

print(f"\n\nDetailed File Breakdown:\n")
print(f"{'File':<50} {'Added':<10} {'Removed':<10}")
print("-" * 70)

for filename, stats in sorted(files.items(), key=lambda x: x[1]['added'], reverse=True)[:15]:
    if any(filename.startswith(prefix) for prefix in ['agentcoord/', 'scripts/', 'tests/']):
        print(f"{filename:<50} {stats['added']:<10,} {stats['removed']:<10,}")

print()
print(f"Total lines added: {total_added:,}")
print(f"Total lines removed: {total_removed:,}")
print(f"Net change: +{total_added - total_removed:,} lines")

# Estimate model breakdown
print(f"\n\nEstimated Model Usage:\n")
print(f"  Sonnet 4.5:  ~{grand_total_tokens:,} tokens  (${grand_total_cost:.4f})")
print(f"  Haiku:       ~{grand_total_tokens // 10:,} tokens  (${(grand_total_tokens // 10 / 1_000_000) * 0.25:.4f}) (planner)")
print(f"\n  Total estimated cost: ${grand_total_cost + (grand_total_tokens // 10 / 1_000_000) * 0.25:.4f}")

print(f"\nNote: These are estimates based on typical usage patterns.")
print(f"Actual usage may vary Â±30% depending on context and iterations.")
